{"train_loss": [], "val_loss": [], "val_pp": [], "val_acc": [], "args": {"config_format": "base", "batch_size": 66, "acc_steps": 1, "seed": 123, "data_seed": 1337, "device": null, "iterations": 25000, "lr": 0.001, "warmup_percent": 0.05, "weight_decay": 0.1, "beta1": 0.9, "beta2": 0.95, "scheduler": "cos", "opt": "adamw", "eval_freq": 200, "results_base_folder": "./exps", "grad_clip": 1.0, "dataset": "slimpajama", "vocab_size": 50304, "data_in_ram": false, "model": "llama2", "use_pretrained": null, "dropout": 0.05, "n_head": 12, "n_layer": 18, "n_embd": 768, "sequence_length": 512, "dtype": null, "bias": false, "compile": false, "rmsnorm_eps": 1e-05, "multiple_of": 256, "run_prefix": null, "exp_name": "llama2_lr0.001_bs66x1_seqlen512/grad_clip=1.0_dropout=0.05_n_layer=18_seed=123", "wandb": true, "wandb_project": "scaling_law_3h", "wandb_entity": "lauzhack-llm", "wandb_run_prefix": "none", "eval_seq_prefix": "Once upon a time", "distributed_backend": null, "save_checkpoint_freq": null, "world_size": 1}}
